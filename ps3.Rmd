---
title: "FINC 584 PS3"
output: pdf_document
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

xfun::pkg_attach2('tidyverse', 'modelsummary', 'knitr')

proj <- dirname(rstudioapi::getSourceEditorContext()$path)
```

## Problem 1.a


```{r p1a}

ak_full <- readxl::read_xlsx(file.path(proj, "AK1991.xlsx"))

x_full <- matrix(data = c(rep(1,nrow(ak_full)), ak_full$edu), ncol = 2)
y_full <- matrix(data = ak_full$logwage)

beta_conventional_full <- solve(t(x_full) %*% x_full)%*%(t(x_full)%*%y_full)

resid_full <- y_full - x_full %*% beta_conventional_full
sigma2_hat_full <- mean(resid_full^2)
beta_conventional_se_full <- sqrt(diag(sigma2_hat_full * 
                                         (solve(t(x_full) %*% x_full))))

kable(data.frame(beta_hat = beta_conventional_full, 
                 beta_se = beta_conventional_se_full,
                 row.names = c("$\\beta_0$", "$\\beta_1$")),
      format = 'pandoc')

```

## Problem 1.b


```{r p1b, warning = F, message = F}
ak<- ak_full %>% slice(1:5000)

## Compute beta_hats for conventional and robust
x <- matrix(data = c(rep(1,nrow(ak)), ak$edu), ncol = 2)
y <- matrix(data = ak$logwage)
beta_conventional <- solve(t(x) %*% x)%*%(t(x)%*%y)
resid <- y - x %*% beta_conventional

## Compute SEs for conventional method
sigma2_hat <- mean(resid^2)
beta_conventional_se <- sqrt(diag(sigma2_hat * (solve(t(x) %*% x))))[2]

## Compute SEs for robust method
sandwich_bread <- solve(t(x) %*% x)
sandwich_meat <- t(x) %*% diag(as.vector(resid)^2)  %*% x

beta_robust_se <- sqrt(diag(sandwich_bread %*% sandwich_meat %*% sandwich_bread))[2]

## Bootstrap
set.seed(0)
beta_hat_bootstrap <- rep(NA, 5000)

for(i in 1:length(beta_hat_bootstrap)){
  ak_sample <- ak[sample(1:5000, replace = T),]
  beta_hat_bootstrap[i] <- lm(logwage ~ edu, data = ak_sample)$coefficients['edu']
}

beta_bootstrap_se <- sd(beta_hat_bootstrap)

kable(data.frame(beta_hat_1_se = c(beta_conventional_se, beta_robust_se, 
                 beta_bootstrap_se), 
                 row.names = c("Conventional", "Robust", "Bootstrap")), 
      )


# ggplot(data = data.frame(beta_hat_bootstrap), aes(x = beta_hat_bootstrap)) +
#   geom_histogram(fill = 'steelblue', color = 'black') +
#   labs(title = 'Distribution of beta_hat_1') +
#   theme_bw() +
#   theme(plot.title = element_text(hjust = 0.5)) 
  

```

The results are pretty much what I expected. All three standard errors are roughly similar. The robust standard errors are larger than the conventional OLS estimators which is expected. The bootstrap method is similar to the other two methods in terms of efficiency. 

## Problem 1C

```{r 1c}

confidence_interval <- function(b, b_se){
  return( abs((b - beta_conventional_full[2]))/b_se < qnorm(.975))
}

conventional_method <- function(x,y){

  beta_conventional <- solve(t(x) %*% x)%*%(t(x)%*%y)
  resid <- y - x %*% beta_conventional

  ## Compute SEs for conventional method
  beta_conventional_se <- sqrt(diag(mean(resid^2) * (solve(t(x) %*% x))))[2]
  
  return(confidence_interval(beta_conventional[2], beta_conventional_se))
}

robust_method <- function(x,y){
  
  beta_conventional <- solve(t(x) %*% x)%*%(t(x)%*%y)
  resid <- y - x %*% beta_conventional
  
  ## Compute SEs for robust method
  sandwich_bread <- solve(t(x) %*% x)
  sandwich_meat <- t(x) %*% diag(as.vector(resid)^2) %*% x
  
  beta_robust_se <- sqrt(diag(sandwich_bread %*% sandwich_meat %*% sandwich_bread))[2]
  
  return(confidence_interval(beta_conventional[2], beta_robust_se))

}


bootstrap_method <- function(data,n,m){
  bootstrap_estimates <- rep(NA, m)
  
  for(i in 1:length(bootstrap_estimates)){
    bootstrap_estimates[i] <- lm(logwage ~ edu, 
                                data = data[sample(1:n, n, replace = T),])$coefficients['edu']
  }

 # return((mean(bootstrap_estimates) - beta_conventional_full[2])/sd(bootstrap_estimates))  

 return(confidence_interval(mean(bootstrap_estimates), sd(bootstrap_estimates)))
  
}


problem1c <- function(n, m, data){
  
  mc_sample <- data[sample(1:nrow(data), n, replace = T),]
  
  x <- matrix(data = c(rep(1,n), mc_sample$edu), ncol = 2)
  y <- matrix(data = mc_sample$logwage)
  
  return(data.frame(n = n, 
                    conventional = conventional_method(x,y),
                    robust = robust_method(x,y),
                    bootstrap = bootstrap_method(mc_sample,n,m)
                    ))
}

iter <- 5000

results <- map_dfr(.x = c(rep(50, iter), rep(100, iter), rep(500, iter)), .f = problem1c, data = ak_full, m = 50) 

results %>% group_by(n) %>% 
  summarize_all( ~sum(.)*100/iter)



```

## Problem 1d


$$ h(\hat{\beta}) = e^{\hat{\beta}_0 + 9\hat{\beta}_1}e^{\frac{\sigma^2}{2}} - e^{\hat{\beta}_0 + 8\hat{\beta}_1}e^{\frac{\sigma^2}{2}} $$
$$ h(\hat{\beta}) = e^{\frac{\sigma^2}{2}} \left( e^{\hat{\beta}_0 + 9\hat{\beta}_1} - e^{\hat{\beta}_0 + 8\hat{\beta}_1}\right)$$
Thus, 
$$ \triangledown h(\hat{\beta}) = \left( e^{\frac{\sigma^2}{2}}\left( e^{\hat{\beta}_0 + 9\hat{\beta}_1} - e^{\hat{\beta}_0 + 8\hat{\beta}_1} \right) , e^{\frac{\sigma^2}{2}}\left( 9e^{\hat{\beta}_0 + 9\hat{\beta}_1} - 8e^{\hat{\beta}_0 + 8\hat{\beta}_1} \right)\right)$$

By the delta method, we have that $$\sqrt(n)(h(\hat{\beta}) - h(\beta)) \rightarrow^{D} N\left(0, \triangledown h(\hat{\beta}) * \Sigma * \triangledown (h(\hat{\beta})^T\right)$$

```{r p1d}

e_sigma <- exp(sigma2_hat_full/2)
b0 <- beta_conventional_full[1]
b1 <- beta_conventional_full[2]

del_h <- matrix(c(e_sigma*(exp(b0 + 9*b1) - exp(b0 + 8*b1)), e_sigma*(9*exp(b0 + 9*b1) - 8*exp(b0 + 8*b1))), ncol = 2)
S <- sigma2_hat_full * (solve(t(x_full) %*% x_full))

beta_hat_1d <- e_sigma*(exp(b0 + 9*b1) - exp(b0 + 8*b1))
beta_hat_1d_se <- sqrt(del_h %*% S %*% t(del_h))

ci_1d <- c(beta_hat_1d - qnorm(.975)*beta_hat_1d_se, beta_hat_1d + qnorm(.975)*beta_hat_1d_se)

ci_1d
```

The resulting confidence interval is `r ci_1d`.



